{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/invictus125/cs598-final-project/blob/main/intraoperative_hypotension_TA_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqAswNcRhPzL"
      },
      "source": [
        "# A Reproduction of:\n",
        "## Predicting intraoperative hypotension using deep learning with waveforms of arterial blood pressure, electroencephalogram, and electrocardiogram\n",
        "\n",
        "Original paper by: Yong-Yeon Jo, Jong-Hwan Jang, Joon-myoung Kwon, Hyung-Chul Lee, Chul-Woo Jung, Seonjeong Byun, Han‐Gil Jeong\n",
        "\n",
        "Reproduction project authored by\n",
        "* Mark Bauer\n",
        "  * mbauer553\n",
        "  * markab5@illinois.edu\n",
        "* Ryan David\n",
        "  * victheone\n",
        "  * invictus125\n",
        "  * radavid2@illinois.edu\n",
        "\n",
        "This project can be found on github https://github.com/invictus125/cs598-final-project.  \n",
        "\n",
        "> Note that this project uses <b>VitalDB, an open biosignal dataset.  All users must agree to the Data Use Agreement below.</b>  If after reviewing the agreement you do not comply, please do not read on and close this window.\n",
        "[Data Use Agreement](https://vitaldb.net/dataset/?query=overview&documentId=13qqajnNZzkN7NZ9aXnaQ-47NWy7kx-a6gbrcEsi-gak&sectionId=h.vcpgs1yemdb5)\n",
        "\n",
        "## Introduction\n",
        "Our project is to perform an approximate reproduction of a paper, which can be found [here](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0272055), on predicting hypotension during surgery from a combination of signals such as mean arterial blood pressure (ABP), electrocardiogram (ECG), and electroencephalogram (EEG) as opposed to ABP alone.  Predicting hypotension is important because it is correlated with many post operation complications, and is actionable.  Please read the original work if you are interested in more detail!\n",
        "\n",
        "## Scope of reproducibility\n",
        "\n",
        "As of the draft on 2024-04-14, we are using what we understand to be a very close replication of the model, with a smaller openly available data set.  Our model currently executes utilizing ABP data from the dataset for predictors and labels, but the EEG and ECG data is randomly created mock data.  The original work also examined more look ahead times.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFa5j_wCxBHy",
        "outputId": "c3b1e756-0f9e-4c98-f27a-7704c8c51d17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torcheval in /usr/local/lib/python3.10/dist-packages (0.0.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torcheval) (4.11.0)\n",
            "Requirement already satisfied: vitaldb in /usr/local/lib/python3.10/dist-packages (1.4.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from vitaldb) (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from vitaldb) (2.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from vitaldb) (2.31.0)\n",
            "Requirement already satisfied: wfdb in /usr/local/lib/python3.10/dist-packages (from vitaldb) (4.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->vitaldb) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->vitaldb) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->vitaldb) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->vitaldb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->vitaldb) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->vitaldb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->vitaldb) (2024.2.2)\n",
            "Requirement already satisfied: SoundFile>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from wfdb->vitaldb) (0.12.1)\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from wfdb->vitaldb) (3.7.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wfdb->vitaldb) (1.11.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb->vitaldb) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb->vitaldb) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb->vitaldb) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb->vitaldb) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb->vitaldb) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb->vitaldb) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->wfdb->vitaldb) (3.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->vitaldb) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from SoundFile>=0.10.0->wfdb->vitaldb) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->SoundFile>=0.10.0->wfdb->vitaldb) (2.22)\n"
          ]
        }
      ],
      "source": [
        "# install dependencies\n",
        "!pip install torcheval\n",
        "!pip install vitaldb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i62VgNP7ufup"
      },
      "source": [
        "## Methodology - Data\n",
        "\n",
        "Methodology - Data\n",
        "Case: a surgery/operation\n",
        "\n",
        "Track: data observed during a case, consisting of a device and type\n",
        "\n",
        "As of the draft on 2024-04-14 we are getting only ABP data and labels looking ahead one minute.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "SXPl5lA6umX-"
      },
      "outputs": [],
      "source": [
        "from functools import partial\n",
        "from io import StringIO\n",
        "from os import listdir, getcwd\n",
        "from torch import FloatTensor, BoolTensor\n",
        "\n",
        "import csv\n",
        "import numpy as np\n",
        "import requests\n",
        "import vitaldb\n",
        "\n",
        "SEGEMENT_LENGTH_SECONDS = 60\n",
        "\n",
        "ABP_TRACK = 'SNUADC/ART'\n",
        "ECG_TRACK = 'SNUADC/ECG_II'\n",
        "EEG_TRACK = 'BIS/EEG1_WAV'\n",
        "\n",
        "RELEVANT_TRACKS = [\n",
        "    ABP_TRACK,\n",
        "    ECG_TRACK,\n",
        "    EEG_TRACK,\n",
        "]\n",
        "\n",
        "def _url_to_reader(url_string):\n",
        "    response = requests.get(url_string)\n",
        "    file = StringIO(response.text)\n",
        "    return csv.DictReader(file, delimiter=',')\n",
        "\n",
        "def get_unique_vals(key, iterable):\n",
        "    return set(map(lambda item: item[key], iterable))\n",
        "\n",
        "def case_filter(case):\n",
        "    return float(case['age']) >= 18.0 and case['ane_type'] == 'General'\n",
        "\n",
        "def _case_track_filter(case_id, case_dict):\n",
        "    track_list = case_dict[case_id]['tracks']\n",
        "    return (\n",
        "        ABP_TRACK in track_list and\n",
        "        ECG_TRACK in track_list and\n",
        "        EEG_TRACK in track_list\n",
        "    )\n",
        "\n",
        "def _get_candidate_cases():\n",
        "    cases_by_id = {}\n",
        "    for case in _url_to_reader('https://api.vitaldb.net/cases'):\n",
        "        if case_filter(case):\n",
        "            case['tracks'] = {}\n",
        "            cases_by_id[case['\\ufeffcaseid']] = case\n",
        "\n",
        "    track_list_reader = _url_to_reader('https://api.vitaldb.net/trks')\n",
        "\n",
        "    for track in track_list_reader:\n",
        "        case_id = track['caseid']\n",
        "        if track['tname'] in RELEVANT_TRACKS:\n",
        "            if cases_by_id.get(case_id):\n",
        "                cases_by_id[case_id]['tracks'][track['tname']] = track['tid']\n",
        "\n",
        "    case_track_filter = partial(_case_track_filter, case_dict=cases_by_id)\n",
        "\n",
        "    return [case_id for case_id in filter(case_track_filter, cases_by_id.keys())]\n",
        "\n",
        "def _get_candidate_cases_from_dir(dir_path):\n",
        "    return [f.split('.vital')[0] for f in listdir(dir_path) if '.vital' in f]\n",
        "\n",
        "def _download_vital_file(case_id):\n",
        "    vf = vitaldb.VitalFile(int(case_id), RELEVANT_TRACKS)\n",
        "    vf.to_vital(case_id+'.vital')\n",
        "\n",
        "def _get_tracks_from_vital_file(path, tracks, sample_rate):\n",
        "    vf = vitaldb.read_vital(path, tracks)\n",
        "    return vf.to_numpy(tracks, sample_rate)\n",
        "\n",
        "def validate_abp_segment(segment):\n",
        "\n",
        "    return (\n",
        "        not np.isnan(segment).any() and\n",
        "        not (segment > 200).any() and\n",
        "        not (segment < 30).any() and\n",
        "        not ((np.max(segment) - np.min(segment)) < 30) and\n",
        "        not (np.abs(np.diff(segment)) > 30).any() # abrupt changes are assumed to be noise\n",
        "    )\n",
        "\n",
        "def download_data(num_requested_cases):\n",
        "    num_downloaded_cases = 0\n",
        "    candidate_case_ids = _get_candidate_cases()\n",
        "\n",
        "    np.random.shuffle(candidate_case_ids)\n",
        "    for case_id in candidate_case_ids:\n",
        "        print('Downloading case:', case_id)\n",
        "        _download_vital_file(case_id)\n",
        "        num_downloaded_cases = num_downloaded_cases + 1\n",
        "        at_requested = num_downloaded_cases == num_requested_cases\n",
        "        if at_requested:\n",
        "            break\n",
        "\n",
        "    if not at_requested:\n",
        "        print('Requsted cases not reached but all available cases exhausted.  ')\n",
        "\n",
        "def get_data(\n",
        "    minutes_ahead,\n",
        "    abp_and_ecg_sample_rate_per_second=500,\n",
        "    eeg_sample_rate_per_second=128,\n",
        "    max_num_samples=None,\n",
        "    max_num_cases=None,\n",
        "    from_dir=None,\n",
        "):\n",
        "    if from_dir is None:\n",
        "        candidate_case_ids = _get_candidate_cases()\n",
        "    else:\n",
        "        candidate_case_ids = _get_candidate_cases_from_dir(from_dir)\n",
        "\n",
        "    abps = []\n",
        "    ecgs = []\n",
        "    eegs = []\n",
        "    hypotension_event_bools = []\n",
        "\n",
        "    abp_data_in_two_seconds = 2 * abp_and_ecg_sample_rate_per_second\n",
        "\n",
        "    at_max = False\n",
        "\n",
        "    case_count = 0\n",
        "    np.random.shuffle(candidate_case_ids)\n",
        "    for case_id in candidate_case_ids:\n",
        "        case_num_samples = 0\n",
        "        case_num_events = 0\n",
        "\n",
        "        print('Getting track data for case:', case_id)\n",
        "        if from_dir is None:\n",
        "            case_tracks = vitaldb.load_case(int(case_id), RELEVANT_TRACKS[0:2], 1/abp_and_ecg_sample_rate_per_second)\n",
        "        else:\n",
        "            case_tracks = _get_tracks_from_vital_file(f\"{from_dir}/{case_id}.vital\", RELEVANT_TRACKS[0:2], 1/abp_and_ecg_sample_rate_per_second)\n",
        "\n",
        "        abp_track = case_tracks[:,0]\n",
        "        # ecg_track = case_tracks[:,1]\n",
        "\n",
        "        # eeg_track = vitaldb.load_case(int(case_id), RELEVANT_TRACKS[2], 1/eeg_sample_rate_per_second).flatten()\n",
        "\n",
        "        for i in range(\n",
        "            0,\n",
        "            len(abp_track) - abp_and_ecg_sample_rate_per_second * (SEGEMENT_LENGTH_SECONDS + (1 + minutes_ahead) * SEGEMENT_LENGTH_SECONDS),\n",
        "            10 * abp_and_ecg_sample_rate_per_second\n",
        "        ):\n",
        "            x_segment = abp_track[i:i + abp_and_ecg_sample_rate_per_second * SEGEMENT_LENGTH_SECONDS]\n",
        "            y_segment_start = i + abp_and_ecg_sample_rate_per_second * (SEGEMENT_LENGTH_SECONDS + minutes_ahead * SEGEMENT_LENGTH_SECONDS)\n",
        "            y_segement_end = i + abp_and_ecg_sample_rate_per_second * (SEGEMENT_LENGTH_SECONDS + (minutes_ahead + 1) * SEGEMENT_LENGTH_SECONDS)\n",
        "            y_segment = abp_track[y_segment_start:y_segement_end]\n",
        "\n",
        "            if validate_abp_segment(x_segment) and validate_abp_segment(y_segment):\n",
        "                abps.append(x_segment)\n",
        "\n",
        "                # 2 second moving average\n",
        "                y_numerator = np.nancumsum(y_segment, dtype=np.float32)\n",
        "                y_numerator[abp_data_in_two_seconds:] = y_numerator[abp_data_in_two_seconds:] - y_numerator[:-abp_data_in_two_seconds]\n",
        "                y_moving_avg = y_numerator[abp_data_in_two_seconds - 1:] / abp_data_in_two_seconds\n",
        "\n",
        "                is_hypotension_event = np.nanmax(y_moving_avg) < 65\n",
        "                hypotension_event_bools.append(is_hypotension_event)\n",
        "                case_num_samples = case_num_samples + 1\n",
        "                if(is_hypotension_event):\n",
        "                    case_num_events = case_num_events + 1\n",
        "\n",
        "            at_max_samples = len(hypotension_event_bools) == max_num_samples\n",
        "            if at_max_samples:\n",
        "                break\n",
        "\n",
        "        case_count = case_count + 1\n",
        "        print(f\"Statistics for case: {case_id}, {case_num_samples} total valid samples, {case_num_events} positive samples\")\n",
        "\n",
        "        if at_max_samples or case_count == max_num_cases:\n",
        "            if at_max_samples:\n",
        "                print('Max samples reached')\n",
        "            else:\n",
        "                print('Max cases reached')\n",
        "            at_max = True\n",
        "            break\n",
        "\n",
        "    if not at_max:\n",
        "        print('Max not reached but all available cases exhausted.  ')\n",
        "\n",
        "    # Shuffle the samples\n",
        "    abps = np.array(abps)\n",
        "    ecgs = np.array(ecgs)\n",
        "    eegs = np.array(eegs)\n",
        "    hypotension_event_bools = np.array(hypotension_event_bools)\n",
        "    shuffled_idx = np.array([i for i in range(0, len(hypotension_event_bools))]).astype(int)\n",
        "    np.random.shuffle(shuffled_idx)\n",
        "    if len(abps) > 0:\n",
        "      abps = abps[shuffled_idx]\n",
        "    if len(ecgs) > 0:\n",
        "      ecgs = ecgs[shuffled_idx]\n",
        "    if len(eegs) > 0:\n",
        "      eegs = eegs[shuffled_idx]\n",
        "    hypotension_event_bools = hypotension_event_bools[shuffled_idx]\n",
        "\n",
        "    return (\n",
        "        FloatTensor(abps).unsqueeze(1),\n",
        "        FloatTensor(ecgs).unsqueeze(1),\n",
        "        FloatTensor(eegs).unsqueeze(1),\n",
        "        BoolTensor(hypotension_event_bools).float(),\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzUkrVE9sERX"
      },
      "source": [
        "## Methodology - Model\n",
        "Our model is an exact reproduction based on the description provided in the original paper.\n",
        "\n",
        "There is a ResNet for each of the three waveform types we handle consisting of:\n",
        "\n",
        "- A CNN encoder layer\n",
        "- 12 residual blocks, each having two convolutions and two batch normalizations. Alternating blocks will halve the length of the data using a max pooling operation. Per the paper, we also added skip connections by summing the input into the output in each residual block.\n",
        "- A fully connected output layer which flattens the channels prior to passing through a NN\n",
        "\n",
        "The model is built such that we can provide one or more ResNets and it will adapt. This is so that we can experiment with varying combinations of input data.\n",
        "\n",
        "Once the input is run through the ResNets, their output is concatenated and passed through a fully connected layer which ends with a sigmoid activation, producing the final prediction.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "QsU7Kh2uuGgw"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import math\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "class EncoderBlock(nn.Module):\n",
        "  def __init__(self, dim_in, kernel_size=15, stride=1):\n",
        "    super(EncoderBlock, self).__init__()\n",
        "    padding = math.floor(kernel_size / 2.0)\n",
        "    self.conv = nn.Conv1d(1, 1, kernel_size, stride, padding=padding)\n",
        "    self.mp = nn.MaxPool1d(kernel_size, stride, padding)\n",
        "    self.fc = nn.Linear(dim_in, dim_in)\n",
        "    torch.nn.init.normal_(self.fc.weight, mean=0.0, std=0.01)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x_hat = self.conv(x)\n",
        "    x_hat = self.mp(x_hat)\n",
        "    return self.fc(x_hat)\n",
        "\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "  def __init__(\n",
        "    self,\n",
        "    in_channels,\n",
        "    out_channels,\n",
        "    size_down,\n",
        "    kernel_size,\n",
        "    stride=1\n",
        "  ):\n",
        "    super(ResidualBlock, self).__init__()\n",
        "\n",
        "    self.size_down = size_down\n",
        "    self.in_channels = in_channels\n",
        "    self.out_channels = out_channels\n",
        "\n",
        "    padding = math.floor(kernel_size / 2.0)\n",
        "\n",
        "    self.bn1 = nn.BatchNorm1d(in_channels)\n",
        "    self.act1 = nn.ReLU()\n",
        "    self.do = nn.Dropout()\n",
        "    self.conv1 = nn.Conv1d(in_channels, in_channels, kernel_size, stride, padding)\n",
        "    self.bn2 = nn.BatchNorm1d(in_channels)\n",
        "    self.act2 = nn.ReLU()\n",
        "    self.conv2 = nn.Conv1d(in_channels, out_channels, kernel_size, stride, padding)\n",
        "    self.mp = nn.MaxPool1d(kernel_size, padding=padding, stride=2)\n",
        "    self.conv_for_input = nn.Conv1d(in_channels, out_channels, kernel_size, stride, padding)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x_hat = self.bn1(x)\n",
        "    x_hat = self.act1(x_hat)\n",
        "    x_hat = self.do(x_hat)\n",
        "    x_hat = self.conv1(x_hat)\n",
        "    x_hat = self.bn2(x_hat)\n",
        "    x_hat = self.act2(x_hat)\n",
        "    x_hat = self.conv2(x_hat)\n",
        "\n",
        "    # Adjust dimensions of input if needed for the skip connection\n",
        "    x_input = None\n",
        "    if self.in_channels != self.out_channels:\n",
        "      x_input = self.conv_for_input(x)\n",
        "    else:\n",
        "      x_input = x\n",
        "\n",
        "    x_hat = x_hat + x_input\n",
        "\n",
        "    if self.size_down:\n",
        "      x_hat = self.mp(x_hat)\n",
        "\n",
        "    return x_hat\n",
        "\n",
        "\n",
        "class FlattenAndLinearBlock(nn.Module):\n",
        "  def __init__(self, dim_in, dim_out):\n",
        "    super(FlattenAndLinearBlock, self).__init__()\n",
        "    self.fc = nn.Linear(dim_in, dim_out)\n",
        "    torch.nn.init.normal_(self.fc.weight, mean=0.0, std=0.01)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x_hat = torch.flatten(x, start_dim=1, end_dim=-1)\n",
        "    x_hat = self.fc(x_hat)\n",
        "\n",
        "    return x_hat\n",
        "\n",
        "\n",
        "class WaveformResNet(nn.Module):\n",
        "  def __init__(\n",
        "    self,\n",
        "    input_shape,\n",
        "    output_size,\n",
        "    data_type\n",
        "  ):\n",
        "    super(WaveformResNet, self).__init__()\n",
        "    self.encoder = EncoderBlock(input_shape, 15, 1)\n",
        "    self.res_in_dim = input_shape\n",
        "    self.output_size = output_size\n",
        "    self.data_type = data_type\n",
        "\n",
        "    if data_type not in ['abp', 'ecg', 'eeg']:\n",
        "      raise ValueError('Invalid data type. Must be one of [abp, ecg, eeg]')\n",
        "\n",
        "    # Set up configurations for residual blocks\n",
        "    residual_configs = []\n",
        "    linear_block_input_length = -1\n",
        "    if data_type in ['abp', 'ecg']:\n",
        "      residual_configs = [\n",
        "        {\n",
        "          'kernel_size': 15,\n",
        "          'in_channels': 1,\n",
        "          'out_channels': 2,\n",
        "          'size_down': True,\n",
        "        },\n",
        "        {\n",
        "          'kernel_size': 15,\n",
        "          'in_channels': 2,\n",
        "          'out_channels': 2,\n",
        "          'size_down': False,\n",
        "        },\n",
        "        {\n",
        "          'kernel_size': 15,\n",
        "          'in_channels': 2,\n",
        "          'out_channels': 2,\n",
        "          'size_down': True,\n",
        "        },\n",
        "        {\n",
        "          'kernel_size': 15,\n",
        "          'in_channels': 2,\n",
        "          'out_channels': 2,\n",
        "          'size_down': False,\n",
        "        },\n",
        "        {\n",
        "          'kernel_size': 15,\n",
        "          'in_channels': 2,\n",
        "          'out_channels': 2,\n",
        "          'size_down': True,\n",
        "        },\n",
        "        {\n",
        "          'kernel_size': 15,\n",
        "          'in_channels': 2,\n",
        "          'out_channels': 4,\n",
        "          'size_down': False,\n",
        "        },\n",
        "        {\n",
        "          'kernel_size': 7,\n",
        "          'in_channels': 4,\n",
        "          'out_channels': 4,\n",
        "          'size_down': True,\n",
        "        },\n",
        "        {\n",
        "          'kernel_size': 7,\n",
        "          'in_channels': 4,\n",
        "          'out_channels': 4,\n",
        "          'size_down': False,\n",
        "        },\n",
        "        {\n",
        "          'kernel_size': 7,\n",
        "          'in_channels': 4,\n",
        "          'out_channels': 4,\n",
        "          'size_down': True,\n",
        "        },\n",
        "        {\n",
        "          'kernel_size': 7,\n",
        "          'in_channels': 4,\n",
        "          'out_channels': 6,\n",
        "          'size_down': False,\n",
        "        },\n",
        "        {\n",
        "          'kernel_size': 7,\n",
        "          'in_channels': 6,\n",
        "          'out_channels': 6,\n",
        "          'size_down': True,\n",
        "        },\n",
        "        {\n",
        "          'kernel_size': 7,\n",
        "          'in_channels': 6,\n",
        "          'out_channels': 6,\n",
        "          'size_down': False,\n",
        "        },\n",
        "      ]\n",
        "      linear_block_input_length = 469 * 6\n",
        "    else:\n",
        "      residual_configs = [\n",
        "        {\n",
        "          'kernel_size': 7,\n",
        "          'in_channels': 1,\n",
        "          'out_channels': 2,\n",
        "          'size_down': True,\n",
        "        },\n",
        "        {\n",
        "          'kernel_size': 7,\n",
        "          'in_channels': 2,\n",
        "          'out_channels': 2,\n",
        "          'size_down': False,\n",
        "        },\n",
        "        {\n",
        "          'kernel_size': 7,\n",
        "          'in_channels': 2,\n",
        "          'out_channels': 2,\n",
        "          'size_down': True,\n",
        "        },\n",
        "        {\n",
        "          'kernel_size': 7,\n",
        "          'in_channels': 2,\n",
        "          'out_channels': 2,\n",
        "          'size_down': False,\n",
        "        },\n",
        "        {\n",
        "          'kernel_size': 7,\n",
        "          'in_channels': 2,\n",
        "          'out_channels': 2,\n",
        "          'size_down': True,\n",
        "        },\n",
        "        {\n",
        "          'kernel_size': 7,\n",
        "          'in_channels': 2,\n",
        "          'out_channels': 4,\n",
        "          'size_down': False,\n",
        "        },\n",
        "        {\n",
        "          'kernel_size': 3,\n",
        "          'in_channels': 4,\n",
        "          'out_channels': 4,\n",
        "          'size_down': True,\n",
        "        },\n",
        "        {\n",
        "          'kernel_size': 3,\n",
        "          'in_channels': 4,\n",
        "          'out_channels': 4,\n",
        "          'size_down': False,\n",
        "        },\n",
        "        {\n",
        "          'kernel_size': 3,\n",
        "          'in_channels': 4,\n",
        "          'out_channels': 4,\n",
        "          'size_down': True,\n",
        "        },\n",
        "        {\n",
        "          'kernel_size': 3,\n",
        "          'in_channels': 4,\n",
        "          'out_channels': 6,\n",
        "          'size_down': False,\n",
        "        },\n",
        "        {\n",
        "          'kernel_size': 3,\n",
        "          'in_channels': 6,\n",
        "          'out_channels': 6,\n",
        "          'size_down': True,\n",
        "        },\n",
        "        {\n",
        "          'kernel_size': 3,\n",
        "          'in_channels': 6,\n",
        "          'out_channels': 6,\n",
        "          'size_down': False,\n",
        "        },\n",
        "      ]\n",
        "      linear_block_input_length = 120 * 6\n",
        "\n",
        "    self.residuals = []\n",
        "    # Build residuals\n",
        "    for i in range(12):\n",
        "      self.residuals.append(\n",
        "        ResidualBlock(\n",
        "          size_down=residual_configs[i]['size_down'],\n",
        "          in_channels=residual_configs[i]['in_channels'],\n",
        "          out_channels=residual_configs[i]['out_channels'],\n",
        "          kernel_size=residual_configs[i]['kernel_size'],\n",
        "        )\n",
        "      )\n",
        "\n",
        "    self.fl_ln = FlattenAndLinearBlock(linear_block_input_length, output_size)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    # TODO: get encoder layer working properly and uncomment\n",
        "    # x_hat = self.encoder(x)\n",
        "    x_hat = x\n",
        "\n",
        "    for i in range(len(self.residuals)):\n",
        "      x_hat = self.residuals[i](x_hat)\n",
        "\n",
        "    out = self.fl_ln(x_hat)\n",
        "\n",
        "    return out\n",
        "\n",
        "\n",
        "  def get_output_size(self):\n",
        "    return self.output_size\n",
        "\n",
        "\n",
        "class IntraoperativeHypotensionModel(nn.Module):\n",
        "  def __init__(\n",
        "    self,\n",
        "    ecg_resnet=None,\n",
        "    abp_resnet=None,\n",
        "    eeg_resnet=None\n",
        "  ):\n",
        "    super(IntraoperativeHypotensionModel, self).__init__()\n",
        "\n",
        "    self.ecg = ecg_resnet\n",
        "    self.abp = abp_resnet\n",
        "    self.eeg = eeg_resnet\n",
        "\n",
        "    self.fc_input_length = 0\n",
        "\n",
        "    if self.ecg is not None:\n",
        "      self.fc_input_length += self.ecg.get_output_size()\n",
        "\n",
        "    if self.abp is not None:\n",
        "      self.fc_input_length += self.abp.get_output_size()\n",
        "\n",
        "    if self.eeg is not None:\n",
        "      self.fc_input_length += self.eeg.get_output_size()\n",
        "\n",
        "    if self.fc_input_length == 0:\n",
        "      raise 'No resnet blocks provided, unable to build model'\n",
        "\n",
        "    self.fc1 = nn.Linear(self.fc_input_length, 16)\n",
        "    self.fc2 = nn.Linear(16, 1)\n",
        "    self.act = nn.Sigmoid()\n",
        "    torch.nn.init.normal_(self.fc1.weight, mean=0.0, std=0.01)\n",
        "    torch.nn.init.normal_(self.fc2.weight, mean=0.0, std=0.01)\n",
        "\n",
        "\n",
        "  def forward(self, abp, ecg, eeg):\n",
        "    ecg_o = torch.Tensor([])\n",
        "    abp_o = torch.Tensor([])\n",
        "    eeg_o = torch.Tensor([])\n",
        "\n",
        "    if self.ecg is not None:\n",
        "      ecg_o = self.ecg(ecg)\n",
        "\n",
        "    if self.abp is not None:\n",
        "      abp_o = self.abp(abp)\n",
        "\n",
        "    if self.eeg is not None:\n",
        "      eeg_o = self.eeg(eeg)\n",
        "\n",
        "    resnet_output = torch.concat([ecg_o, abp_o, eeg_o], dim=1)\n",
        "\n",
        "    intermediate = self.fc1(resnet_output)\n",
        "    intermediate = self.fc2(intermediate)\n",
        "    prediction = self.act(intermediate)\n",
        "\n",
        "    return prediction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WysHaY2luLRS"
      },
      "source": [
        "## Methodology - Training\n",
        "Computational requirements:\n",
        "- At least 50 GB of RAM\n",
        "- GPU instance (we have been experimenting with an A100)\n",
        "\n",
        "The training of this model is fairly straightforward. The paper suggested that we should use Adam as the optimizer and BCE as the loss function, so that is what we have done.\n",
        "\n",
        "Each training epoch will also automatically run evaluation on both the train set and the validation set. See the evaluation methodology for details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "r_CMSJdxt3Fp"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.optim import Adam\n",
        "from torch.nn import BCELoss\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def _extract_batch(data, batch_size, batch_number):\n",
        "  start = batch_size * batch_number\n",
        "  end = start + batch_size\n",
        "\n",
        "  if start >= len(data[3]):\n",
        "    return None\n",
        "\n",
        "  return [\n",
        "      data[0][start:end] if len(data[0]) > 0 else None,\n",
        "      data[1][start:end] if len(data[1]) > 0 else None,\n",
        "      data[2][start:end] if len(data[2]) > 0 else None,\n",
        "      data[3][start:end]\n",
        "  ]\n",
        "\n",
        "\n",
        "def _train_one_epoch(\n",
        "  model,\n",
        "  train_data,\n",
        "  optimizer,\n",
        "  criterion,\n",
        "  batch_size=32\n",
        "):\n",
        "  model.train()\n",
        "  loss_history = []\n",
        "\n",
        "  batch_num = 0\n",
        "  batch = _extract_batch(train_data, batch_size, batch_num)\n",
        "  while batch is not None:\n",
        "    optimizer.zero_grad()\n",
        "    abp = batch[0]\n",
        "    ecg = batch[1]\n",
        "    eeg = batch[2]\n",
        "    y = batch[3]\n",
        "    y_hat = model(abp, ecg, eeg)\n",
        "    y_hat = torch.squeeze(y_hat, dim=-1)\n",
        "    loss = criterion(y_hat, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    batch_loss = loss.item()\n",
        "    print(f'\\tBatch {batch_num} loss: {batch_loss}')\n",
        "    loss_history.append(batch_loss)\n",
        "\n",
        "    batch_num += 1\n",
        "    batch = _extract_batch(train_data, batch_size, batch_num)\n",
        "\n",
        "  return loss_history\n",
        "\n",
        "\n",
        "def train(\n",
        "  model,\n",
        "  train_data_handle,\n",
        "  test_data_handle,\n",
        "  learning_rate=0.0001,\n",
        "  epochs=100,\n",
        "  suspend_train_epochs_threshold=5,\n",
        "  batch_size=32\n",
        "):\n",
        "  \"\"\"Trains an IntraoperativeHypotensionModel using the given learning rate for\n",
        "  the given number of epochs\n",
        "\n",
        "  model: the IntraoperativeHypotensionModel to train\n",
        "  train_data_handle: the dataset we will train on\n",
        "  test_data_handle: the dataset we will use for evaluation\n",
        "  learning_rate: the learning rate to use with the Adam optimizer\n",
        "  epochs: the number of epochs to train for\n",
        "  suspend_train_epochs_threshold: training will be suspended if the loss does\n",
        "    not improve for this number of epochs\n",
        "  \"\"\"\n",
        "  if model is None or train_data_handle is None or test_data_handle is None:\n",
        "    raise ValueError(\n",
        "      'model, train_data_handle, and test_data_handle are required for training'\n",
        "    )\n",
        "\n",
        "  criterion = BCELoss()\n",
        "  optimizer = Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "  overall_loss_history = []\n",
        "  consecutive_epochs_without_improvement = 0\n",
        "  for epoch in range(epochs):\n",
        "    print('====================================')\n",
        "    print(f'     Epoch #{epoch + 1}')\n",
        "    print('====================================')\n",
        "\n",
        "    loss_history = _train_one_epoch(\n",
        "      model,\n",
        "      train_data_handle,\n",
        "      optimizer,\n",
        "      criterion,\n",
        "      batch_size\n",
        "    )\n",
        "    eval_model(model, train_data_handle, 'Train', batch_size)\n",
        "    # Not using performance metrics yet in this function.\n",
        "    # Potential TODO: stop training once desired performance is reached (TBD)\n",
        "    performance = eval_model(model, test_data_handle, 'Test', batch_size)\n",
        "\n",
        "    if epoch > 0:\n",
        "      mean_loss = np.mean(loss_history)\n",
        "      overall_loss_history.append(mean_loss)\n",
        "      loss_change = overall_loss_history[epoch - 1] - mean_loss\n",
        "      if loss_change < 0.1:\n",
        "        consecutive_epochs_without_improvement += 1\n",
        "      else:\n",
        "        consecutive_epochs_without_improvement = 0\n",
        "\n",
        "    if consecutive_epochs_without_improvement >= suspend_train_epochs_threshold:\n",
        "      print(f'Training stopping after {epoch+1} epochs.')\n",
        "      print(f'Loss did not change for {suspend_train_epochs_threshold} epochs')\n",
        "      break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUrbzCCLttmN"
      },
      "source": [
        "##  Methodology - Evaluation\n",
        "The original paper uses four metrics:\n",
        "- AUROC\n",
        "- AUPRC\n",
        "- Sensitivity\n",
        "- Specificity\n",
        "\n",
        "We chose to use the torcheval library for our metrics, except for binary specificity which did not appear to be present in torcheval.\n",
        "\n",
        "In light of that, we have implemented our own binary specificity. Regrettably, this does not yet work properly, but we will do our best to get it functional before our final submission.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "jh1fdvuctwgX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torcheval.metrics import BinaryAUROC, BinaryAUPRC, BinaryRecall\n",
        "\n",
        "\n",
        "def _binary_specificity(test, target):\n",
        "  # TN / TN + FP\n",
        "  pinned = torch.where(test >= 0.5, 1.0, 0.0)\n",
        "  pos = torch.where(pinned > 0, 1.0, 0.0)\n",
        "  neg = torch.where(pinned < 1, 1.0, 0.0)\n",
        "  gt_pos = torch.where(target > 0, 1.0, 0.0)\n",
        "  gt_neg = torch.where(target < 1, 1.0, 0.0)\n",
        "  tn = neg + gt_neg\n",
        "  tn = torch.sum(torch.where(tn > 1, 1.0, 0.0), dtype=torch.float)\n",
        "  fp = pos + gt_neg\n",
        "  fp = torch.sum(torch.where(fp > 1, 1.0, 0.0), dtype=torch.float)\n",
        "\n",
        "  return (tn / (tn + fp))\n",
        "\n",
        "\n",
        "def eval_model(\n",
        "  model,\n",
        "  eval_data,\n",
        "  dataset_name,\n",
        "  batch_size=32\n",
        "):\n",
        "  model.eval()\n",
        "\n",
        "  auroc = []\n",
        "  auprc = []\n",
        "  sensitivity = []\n",
        "  specificity = []\n",
        "\n",
        "  f_auroc = BinaryAUROC()\n",
        "  f_auprc = BinaryAUPRC()\n",
        "  f_sensitivity = BinaryRecall()\n",
        "\n",
        "  batch_num = 0\n",
        "  batch = _extract_batch(eval_data, batch_size, batch_num)\n",
        "  while batch is not None:\n",
        "    abp = batch[0]\n",
        "    ecg = batch[1]\n",
        "    eeg = batch[2]\n",
        "    y = batch[3]\n",
        "\n",
        "    y_hat = model(abp, ecg, eeg)\n",
        "    y_hat = y_hat.squeeze(-1)\n",
        "\n",
        "    y_hat_long = torch.where(y_hat >= 0.5, 1.0, 0.0).long()\n",
        "    target_long = y.long()\n",
        "\n",
        "    print(f'y_hat_long sum: {y_hat_long.sum()}, target_long sum: {target_long.sum()}')\n",
        "\n",
        "    f_auroc.update(y_hat, y)\n",
        "    f_auprc.update(y_hat, y)\n",
        "    f_sensitivity.update(y_hat_long, target_long)\n",
        "\n",
        "    auroc.append(f_auroc.compute())\n",
        "    auprc.append(f_auprc.compute())\n",
        "    sensitivity.append(f_sensitivity.compute())\n",
        "    specificity.append(_binary_specificity(y_hat, y))\n",
        "\n",
        "    batch_num += 1\n",
        "    batch = _extract_batch(eval_data, batch_size, batch_num)\n",
        "\n",
        "  print(sensitivity)\n",
        "  m_auroc = np.mean(auroc)\n",
        "  m_auprc = np.mean(auprc)\n",
        "  m_sensitivity = np.mean(sensitivity)\n",
        "  m_specificity = np.mean(specificity)\n",
        "\n",
        "  print(f'    {dataset_name} data metrics:')\n",
        "  print(f'        AUROC: {m_auroc}')\n",
        "  print(f'        AUPRC: {m_auprc}')\n",
        "  print(f'        Sensitivity: {m_sensitivity}')\n",
        "  print(f'        Specificity: {m_specificity}')\n",
        "\n",
        "  return m_auroc, m_auprc, m_sensitivity, m_specificity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTM5yt6WtOdP"
      },
      "source": [
        "\n",
        "### Results\n",
        "Thus far we have the ability to build our model and obtain one type of test data in the form we need it for training and evaluation. Please execute the code cells below to see for yourself!\n",
        "\n",
        "Our plans from here until the end of the project are:\n",
        "\n",
        "- Make it possible to obtain the other two data types (ECG and EEG) and use them the same way we are able to use ABP\n",
        "- Get our custom specificity function working properly\n",
        "- Train and evaluate our model using a variety of samples\n",
        "- Train and evaluate our model using varying combinations of the input types\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train with only ABP\n",
        "\n",
        "This next section will demonstrate training on only ABP data. It also demonstrates the scalability of our model, allowing us to only use certain resnets if we so choose."
      ],
      "metadata": {
        "id": "FKRTyrR78oeV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Put together a model using only ABP\n",
        "abp_resnet = WaveformResNet(\n",
        "    input_shape=30000,\n",
        "    output_size=32,\n",
        "    data_type='abp',\n",
        ")\n",
        "\n",
        "abp_model = IntraoperativeHypotensionModel(\n",
        "    abp_resnet=abp_resnet\n",
        ")"
      ],
      "metadata": {
        "id": "-FeXoi8R83dh"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtain ABP data to train on\n",
        "test_set = get_data(3, max_num_samples=1000)\n",
        "\n",
        "# Get 819\n",
        "_download_vital_file('819')\n",
        "\n",
        "train_set = get_data(3, from_dir='.')"
      ],
      "metadata": {
        "id": "--44au29-IRD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b45e2c0d-9925-4aad-9364-6fd430fd52c5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting track data for case: 1750\n",
            "Statistics for case: 1750, 0 total valid samples, 0 positive samples\n",
            "Getting track data for case: 3704\n",
            "Statistics for case: 3704, 1000 total valid samples, 94 positive samples\n",
            "Max samples reached\n",
            "Getting track data for case: 819\n",
            "Statistics for case: 819, 737 total valid samples, 73 positive samples\n",
            "Max not reached but all available cases exhausted.  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model on ABP data\n",
        "\n",
        "# train_set = [\n",
        "#     all_data[0][0:4000].unsqueeze(1),\n",
        "#     all_data[1][0:4000].unsqueeze(1),\n",
        "#     all_data[2][0:4000].unsqueeze(1),\n",
        "#     all_data[3][0:4000]\n",
        "# ]\n",
        "\n",
        "# test_set = [\n",
        "#     all_data[0][4000:].unsqueeze(1),\n",
        "#     all_data[1][4000:].unsqueeze(1),\n",
        "#     all_data[2][4000:].unsqueeze(1),\n",
        "#     all_data[3][4000:]\n",
        "# ]\n",
        "\n",
        "# train(abp_model, train_set, test_set, batch_size=40, epochs=100, learning_rate=0.0001)\n",
        "\n",
        "# TRAIN ON ONLY CASE 819\n",
        "\n",
        "train(abp_model, train_set, test_set, batch_size=40)\n",
        "\n",
        "# TEST WITH RANDOM DATA\n",
        "# sample_size = 400\n",
        "# train_set_r = [\n",
        "#     torch.randn([sample_size, 1, 30000]),\n",
        "#     torch.randn([sample_size, 1, 30000]),\n",
        "#     torch.randn([sample_size, 1, 30000]),\n",
        "#     torch.where(torch.rand([sample_size]) > 0.5, 1.0, 0.0),\n",
        "# ]\n",
        "\n",
        "# train(abp_model, train_set_r, train_set_r, batch_size=40, epochs=3)\n"
      ],
      "metadata": {
        "id": "Uurpy92P9TXg",
        "outputId": "2489ff4b-f0dd-46ca-eaad-40267db3198e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================================\n",
            "     Epoch #1\n",
            "====================================\n",
            "\tBatch 0 loss: 0.7868557572364807\n",
            "\tBatch 1 loss: 0.7844471335411072\n",
            "\tBatch 2 loss: 0.7544103860855103\n",
            "\tBatch 3 loss: 0.7547532320022583\n",
            "\tBatch 4 loss: 0.7390578985214233\n",
            "\tBatch 5 loss: 0.7296877503395081\n",
            "\tBatch 6 loss: 0.7051376700401306\n",
            "\tBatch 7 loss: 0.6989387273788452\n",
            "\tBatch 8 loss: 0.6848915219306946\n",
            "\tBatch 9 loss: 0.665812075138092\n",
            "\tBatch 10 loss: 0.6529740691184998\n",
            "\tBatch 11 loss: 0.6330965161323547\n",
            "\tBatch 12 loss: 0.615434467792511\n",
            "\tBatch 13 loss: 0.600544810295105\n",
            "\tBatch 14 loss: 0.5802755355834961\n",
            "\tBatch 15 loss: 0.5752568244934082\n",
            "\tBatch 16 loss: 0.5482537150382996\n",
            "\tBatch 17 loss: 0.5135014057159424\n",
            "\tBatch 18 loss: 0.5068650841712952\n",
            "y_hat_long sum: 0, target_long sum: 4\n",
            "y_hat_long sum: 0, target_long sum: 2\n",
            "y_hat_long sum: 0, target_long sum: 6\n",
            "y_hat_long sum: 0, target_long sum: 3\n",
            "y_hat_long sum: 0, target_long sum: 4\n",
            "y_hat_long sum: 0, target_long sum: 2\n",
            "y_hat_long sum: 0, target_long sum: 9\n",
            "y_hat_long sum: 0, target_long sum: 2\n",
            "y_hat_long sum: 0, target_long sum: 6\n",
            "y_hat_long sum: 0, target_long sum: 1\n",
            "y_hat_long sum: 0, target_long sum: 5\n",
            "y_hat_long sum: 0, target_long sum: 2\n",
            "y_hat_long sum: 0, target_long sum: 4\n",
            "y_hat_long sum: 0, target_long sum: 4\n",
            "y_hat_long sum: 0, target_long sum: 3\n",
            "y_hat_long sum: 0, target_long sum: 6\n",
            "y_hat_long sum: 0, target_long sum: 5\n",
            "y_hat_long sum: 0, target_long sum: 3\n",
            "y_hat_long sum: 0, target_long sum: 2\n",
            "[tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.)]\n",
            "    Train data metrics:\n",
            "        AUROC: 0.7441352818508199\n",
            "        AUPRC: 0.27074262499809265\n",
            "        Sensitivity: 0.0\n",
            "        Specificity: 1.0\n",
            "y_hat_long sum: 0, target_long sum: 8\n",
            "y_hat_long sum: 0, target_long sum: 6\n",
            "y_hat_long sum: 0, target_long sum: 5\n",
            "y_hat_long sum: 0, target_long sum: 7\n",
            "y_hat_long sum: 0, target_long sum: 4\n",
            "y_hat_long sum: 0, target_long sum: 1\n",
            "y_hat_long sum: 0, target_long sum: 5\n",
            "y_hat_long sum: 0, target_long sum: 2\n",
            "y_hat_long sum: 0, target_long sum: 1\n",
            "y_hat_long sum: 0, target_long sum: 4\n",
            "y_hat_long sum: 0, target_long sum: 2\n",
            "y_hat_long sum: 0, target_long sum: 5\n",
            "y_hat_long sum: 0, target_long sum: 4\n",
            "y_hat_long sum: 0, target_long sum: 3\n",
            "y_hat_long sum: 0, target_long sum: 2\n",
            "y_hat_long sum: 0, target_long sum: 4\n",
            "y_hat_long sum: 0, target_long sum: 3\n",
            "y_hat_long sum: 0, target_long sum: 2\n",
            "y_hat_long sum: 0, target_long sum: 3\n",
            "y_hat_long sum: 0, target_long sum: 4\n",
            "y_hat_long sum: 0, target_long sum: 2\n",
            "y_hat_long sum: 0, target_long sum: 2\n",
            "y_hat_long sum: 0, target_long sum: 3\n",
            "y_hat_long sum: 0, target_long sum: 7\n",
            "y_hat_long sum: 0, target_long sum: 5\n",
            "[tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.)]\n",
            "    Test data metrics:\n",
            "        AUROC: 0.9835594410849126\n",
            "        AUPRC: 0.8336618542671204\n",
            "        Sensitivity: 0.0\n",
            "        Specificity: 1.0\n",
            "====================================\n",
            "     Epoch #2\n",
            "====================================\n",
            "\tBatch 0 loss: 0.48415812849998474\n",
            "\tBatch 1 loss: 0.44354239106178284\n",
            "\tBatch 2 loss: 0.4788814187049866\n",
            "\tBatch 3 loss: 0.41655802726745605\n",
            "\tBatch 4 loss: 0.42011183500289917\n",
            "\tBatch 5 loss: 0.34075072407722473\n",
            "\tBatch 6 loss: 0.5196105241775513\n",
            "\tBatch 7 loss: 0.305830717086792\n",
            "\tBatch 8 loss: 0.42359447479248047\n",
            "\tBatch 9 loss: 0.24931120872497559\n",
            "\tBatch 10 loss: 0.3724260926246643\n",
            "\tBatch 11 loss: 0.2584088444709778\n",
            "\tBatch 12 loss: 0.3061326742172241\n",
            "\tBatch 13 loss: 0.3181622624397278\n",
            "\tBatch 14 loss: 0.29167574644088745\n",
            "\tBatch 15 loss: 0.38700586557388306\n",
            "\tBatch 16 loss: 0.33431848883628845\n",
            "\tBatch 17 loss: 0.2574848234653473\n",
            "\tBatch 18 loss: 0.32824477553367615\n",
            "y_hat_long sum: 0, target_long sum: 4\n",
            "y_hat_long sum: 0, target_long sum: 2\n",
            "y_hat_long sum: 0, target_long sum: 6\n",
            "y_hat_long sum: 0, target_long sum: 3\n",
            "y_hat_long sum: 0, target_long sum: 4\n",
            "y_hat_long sum: 0, target_long sum: 2\n",
            "y_hat_long sum: 0, target_long sum: 9\n",
            "y_hat_long sum: 0, target_long sum: 2\n",
            "y_hat_long sum: 0, target_long sum: 6\n",
            "y_hat_long sum: 0, target_long sum: 1\n",
            "y_hat_long sum: 0, target_long sum: 5\n",
            "y_hat_long sum: 0, target_long sum: 2\n",
            "y_hat_long sum: 0, target_long sum: 4\n",
            "y_hat_long sum: 0, target_long sum: 4\n",
            "y_hat_long sum: 0, target_long sum: 3\n",
            "y_hat_long sum: 0, target_long sum: 6\n",
            "y_hat_long sum: 0, target_long sum: 5\n",
            "y_hat_long sum: 0, target_long sum: 3\n",
            "y_hat_long sum: 0, target_long sum: 2\n",
            "[tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.)]\n",
            "    Train data metrics:\n",
            "        AUROC: 0.7458164253213654\n",
            "        AUPRC: 0.26965007185935974\n",
            "        Sensitivity: 0.0\n",
            "        Specificity: 1.0\n",
            "y_hat_long sum: 0, target_long sum: 8\n",
            "y_hat_long sum: 0, target_long sum: 6\n",
            "y_hat_long sum: 0, target_long sum: 5\n",
            "y_hat_long sum: 0, target_long sum: 7\n",
            "y_hat_long sum: 0, target_long sum: 4\n",
            "y_hat_long sum: 0, target_long sum: 1\n",
            "y_hat_long sum: 0, target_long sum: 5\n",
            "y_hat_long sum: 0, target_long sum: 2\n",
            "y_hat_long sum: 0, target_long sum: 1\n",
            "y_hat_long sum: 0, target_long sum: 4\n",
            "y_hat_long sum: 0, target_long sum: 2\n",
            "y_hat_long sum: 0, target_long sum: 5\n",
            "y_hat_long sum: 0, target_long sum: 4\n",
            "y_hat_long sum: 0, target_long sum: 3\n",
            "y_hat_long sum: 0, target_long sum: 2\n",
            "y_hat_long sum: 0, target_long sum: 4\n",
            "y_hat_long sum: 0, target_long sum: 3\n",
            "y_hat_long sum: 0, target_long sum: 2\n",
            "y_hat_long sum: 0, target_long sum: 3\n",
            "y_hat_long sum: 0, target_long sum: 4\n",
            "y_hat_long sum: 0, target_long sum: 2\n",
            "y_hat_long sum: 0, target_long sum: 2\n",
            "y_hat_long sum: 0, target_long sum: 3\n",
            "y_hat_long sum: 0, target_long sum: 7\n",
            "y_hat_long sum: 0, target_long sum: 5\n",
            "[tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.)]\n",
            "    Test data metrics:\n",
            "        AUROC: 0.9834892778838644\n",
            "        AUPRC: 0.8286092877388\n",
            "        Sensitivity: 0.0\n",
            "        Specificity: 1.0\n",
            "====================================\n",
            "     Epoch #3\n",
            "====================================\n",
            "\tBatch 0 loss: 0.30106478929519653\n",
            "\tBatch 1 loss: 0.2391849309206009\n",
            "\tBatch 2 loss: 0.4127950668334961\n",
            "\tBatch 3 loss: 0.26524752378463745\n",
            "\tBatch 4 loss: 0.3312738537788391\n",
            "\tBatch 5 loss: 0.1715000420808792\n",
            "\tBatch 6 loss: 0.6469920873641968\n",
            "\tBatch 7 loss: 0.18018445372581482\n",
            "\tBatch 8 loss: 0.4513735771179199\n",
            "\tBatch 9 loss: 0.13379237055778503\n",
            "\tBatch 10 loss: 0.38392728567123413\n",
            "\tBatch 11 loss: 0.19251441955566406\n",
            "\tBatch 12 loss: 0.2874743342399597\n",
            "\tBatch 13 loss: 0.3140927255153656\n",
            "\tBatch 14 loss: 0.28269392251968384\n",
            "\tBatch 15 loss: 0.41176944971084595\n",
            "\tBatch 16 loss: 0.3440190851688385\n",
            "\tBatch 17 loss: 0.2526443302631378\n",
            "\tBatch 18 loss: 0.3334503173828125\n",
            "y_hat_long sum: 0, target_long sum: 4\n",
            "y_hat_long sum: 0, target_long sum: 2\n",
            "y_hat_long sum: 0, target_long sum: 6\n",
            "y_hat_long sum: 0, target_long sum: 3\n",
            "y_hat_long sum: 0, target_long sum: 4\n",
            "y_hat_long sum: 0, target_long sum: 2\n",
            "y_hat_long sum: 0, target_long sum: 9\n",
            "y_hat_long sum: 0, target_long sum: 2\n",
            "y_hat_long sum: 0, target_long sum: 6\n",
            "y_hat_long sum: 0, target_long sum: 1\n",
            "y_hat_long sum: 0, target_long sum: 5\n",
            "y_hat_long sum: 0, target_long sum: 2\n",
            "y_hat_long sum: 0, target_long sum: 4\n",
            "y_hat_long sum: 0, target_long sum: 4\n",
            "y_hat_long sum: 0, target_long sum: 3\n",
            "y_hat_long sum: 0, target_long sum: 6\n",
            "y_hat_long sum: 0, target_long sum: 5\n",
            "y_hat_long sum: 0, target_long sum: 3\n",
            "y_hat_long sum: 0, target_long sum: 2\n",
            "[tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.)]\n",
            "    Train data metrics:\n",
            "        AUROC: 0.7470712784542468\n",
            "        AUPRC: 0.28185757994651794\n",
            "        Sensitivity: 0.0\n",
            "        Specificity: 1.0\n",
            "y_hat_long sum: 0, target_long sum: 8\n",
            "y_hat_long sum: 0, target_long sum: 6\n",
            "y_hat_long sum: 0, target_long sum: 5\n",
            "y_hat_long sum: 0, target_long sum: 7\n",
            "y_hat_long sum: 0, target_long sum: 4\n",
            "y_hat_long sum: 0, target_long sum: 1\n",
            "y_hat_long sum: 0, target_long sum: 5\n",
            "y_hat_long sum: 0, target_long sum: 2\n",
            "y_hat_long sum: 0, target_long sum: 1\n",
            "y_hat_long sum: 0, target_long sum: 4\n",
            "y_hat_long sum: 0, target_long sum: 2\n",
            "y_hat_long sum: 0, target_long sum: 5\n",
            "y_hat_long sum: 0, target_long sum: 4\n",
            "y_hat_long sum: 0, target_long sum: 3\n",
            "y_hat_long sum: 0, target_long sum: 2\n",
            "y_hat_long sum: 0, target_long sum: 4\n",
            "y_hat_long sum: 0, target_long sum: 3\n",
            "y_hat_long sum: 0, target_long sum: 2\n",
            "y_hat_long sum: 0, target_long sum: 3\n",
            "y_hat_long sum: 0, target_long sum: 4\n",
            "y_hat_long sum: 0, target_long sum: 2\n",
            "y_hat_long sum: 0, target_long sum: 2\n",
            "y_hat_long sum: 0, target_long sum: 3\n",
            "y_hat_long sum: 0, target_long sum: 7\n",
            "y_hat_long sum: 0, target_long sum: 5\n",
            "[tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.)]\n",
            "    Test data metrics:\n",
            "        AUROC: 0.9833950839165685\n",
            "        AUPRC: 0.830232560634613\n",
            "        Sensitivity: 0.0\n",
            "        Specificity: 1.0\n",
            "====================================\n",
            "     Epoch #4\n",
            "====================================\n",
            "\tBatch 0 loss: 0.3025292158126831\n",
            "\tBatch 1 loss: 0.23700706660747528\n",
            "\tBatch 2 loss: 0.41063961386680603\n",
            "\tBatch 3 loss: 0.2649271786212921\n",
            "\tBatch 4 loss: 0.327152818441391\n",
            "\tBatch 5 loss: 0.17980606853961945\n",
            "\tBatch 6 loss: 0.6004411578178406\n",
            "\tBatch 7 loss: 0.19052653014659882\n",
            "\tBatch 8 loss: 0.42462247610092163\n",
            "\tBatch 9 loss: 0.1540416181087494\n",
            "\tBatch 10 loss: 0.3641895055770874\n",
            "\tBatch 11 loss: 0.20714788138866425\n",
            "\tBatch 12 loss: 0.2865421772003174\n",
            "\tBatch 13 loss: 0.30803436040878296\n",
            "\tBatch 14 loss: 0.28131183981895447\n",
            "\tBatch 15 loss: 0.3898082971572876\n",
            "\tBatch 16 loss: 0.33279117941856384\n",
            "\tBatch 17 loss: 0.2573656737804413\n",
            "\tBatch 18 loss: 0.32500818371772766\n",
            "y_hat_long sum: 0, target_long sum: 4\n",
            "y_hat_long sum: 0, target_long sum: 2\n",
            "y_hat_long sum: 0, target_long sum: 6\n",
            "y_hat_long sum: 0, target_long sum: 3\n",
            "y_hat_long sum: 0, target_long sum: 4\n",
            "y_hat_long sum: 0, target_long sum: 2\n",
            "y_hat_long sum: 0, target_long sum: 9\n",
            "y_hat_long sum: 0, target_long sum: 2\n",
            "y_hat_long sum: 0, target_long sum: 6\n",
            "y_hat_long sum: 0, target_long sum: 1\n",
            "y_hat_long sum: 0, target_long sum: 5\n",
            "y_hat_long sum: 0, target_long sum: 2\n",
            "y_hat_long sum: 0, target_long sum: 4\n",
            "y_hat_long sum: 0, target_long sum: 4\n",
            "y_hat_long sum: 0, target_long sum: 3\n",
            "y_hat_long sum: 0, target_long sum: 6\n",
            "y_hat_long sum: 0, target_long sum: 5\n",
            "y_hat_long sum: 0, target_long sum: 3\n",
            "y_hat_long sum: 0, target_long sum: 2\n",
            "[tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.)]\n",
            "    Train data metrics:\n",
            "        AUROC: 0.7537328549254303\n",
            "        AUPRC: 0.2850961983203888\n",
            "        Sensitivity: 0.0\n",
            "        Specificity: 1.0\n",
            "y_hat_long sum: 0, target_long sum: 8\n",
            "y_hat_long sum: 0, target_long sum: 6\n",
            "y_hat_long sum: 0, target_long sum: 5\n",
            "y_hat_long sum: 0, target_long sum: 7\n",
            "y_hat_long sum: 0, target_long sum: 4\n",
            "y_hat_long sum: 0, target_long sum: 1\n",
            "y_hat_long sum: 0, target_long sum: 5\n",
            "y_hat_long sum: 0, target_long sum: 2\n",
            "y_hat_long sum: 0, target_long sum: 1\n",
            "y_hat_long sum: 0, target_long sum: 4\n",
            "y_hat_long sum: 0, target_long sum: 2\n",
            "y_hat_long sum: 0, target_long sum: 5\n",
            "y_hat_long sum: 0, target_long sum: 4\n",
            "y_hat_long sum: 0, target_long sum: 3\n",
            "y_hat_long sum: 0, target_long sum: 2\n",
            "y_hat_long sum: 0, target_long sum: 4\n",
            "y_hat_long sum: 0, target_long sum: 3\n",
            "y_hat_long sum: 0, target_long sum: 2\n",
            "y_hat_long sum: 0, target_long sum: 3\n",
            "y_hat_long sum: 0, target_long sum: 4\n",
            "y_hat_long sum: 0, target_long sum: 2\n",
            "y_hat_long sum: 0, target_long sum: 2\n",
            "y_hat_long sum: 0, target_long sum: 3\n",
            "y_hat_long sum: 0, target_long sum: 7\n",
            "y_hat_long sum: 0, target_long sum: 5\n",
            "[tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.)]\n",
            "    Test data metrics:\n",
            "        AUROC: 0.9832856259398537\n",
            "        AUPRC: 0.8265958428382874\n",
            "        Sensitivity: 0.0\n",
            "        Specificity: 1.0\n",
            "====================================\n",
            "     Epoch #5\n",
            "====================================\n",
            "\tBatch 0 loss: 0.30123645067214966\n",
            "\tBatch 1 loss: 0.24206361174583435\n",
            "\tBatch 2 loss: 0.39619016647338867\n",
            "\tBatch 3 loss: 0.26776328682899475\n",
            "\tBatch 4 loss: 0.3236534595489502\n",
            "\tBatch 5 loss: 0.18991099298000336\n",
            "\tBatch 6 loss: 0.5766922831535339\n",
            "\tBatch 7 loss: 0.1966184377670288\n",
            "\tBatch 8 loss: 0.4191822409629822\n",
            "\tBatch 9 loss: 0.15954585373401642\n",
            "\tBatch 10 loss: 0.36253196001052856\n",
            "\tBatch 11 loss: 0.2087736576795578\n",
            "\tBatch 12 loss: 0.2856925129890442\n",
            "\tBatch 13 loss: 0.3083980083465576\n",
            "\tBatch 14 loss: 0.2802884578704834\n",
            "\tBatch 15 loss: 0.39083725214004517\n",
            "\tBatch 16 loss: 0.33294305205345154\n",
            "\tBatch 17 loss: 0.2560243010520935\n",
            "\tBatch 18 loss: 0.32500433921813965\n",
            "y_hat_long sum: 0, target_long sum: 4\n",
            "y_hat_long sum: 0, target_long sum: 2\n",
            "y_hat_long sum: 0, target_long sum: 6\n",
            "y_hat_long sum: 0, target_long sum: 3\n",
            "y_hat_long sum: 0, target_long sum: 4\n",
            "y_hat_long sum: 0, target_long sum: 2\n",
            "y_hat_long sum: 0, target_long sum: 9\n",
            "y_hat_long sum: 0, target_long sum: 2\n",
            "y_hat_long sum: 0, target_long sum: 6\n",
            "y_hat_long sum: 0, target_long sum: 1\n",
            "y_hat_long sum: 0, target_long sum: 5\n",
            "y_hat_long sum: 0, target_long sum: 2\n",
            "y_hat_long sum: 0, target_long sum: 4\n",
            "y_hat_long sum: 0, target_long sum: 4\n",
            "y_hat_long sum: 0, target_long sum: 3\n",
            "y_hat_long sum: 0, target_long sum: 6\n",
            "y_hat_long sum: 0, target_long sum: 5\n",
            "y_hat_long sum: 0, target_long sum: 3\n",
            "y_hat_long sum: 0, target_long sum: 2\n",
            "[tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.)]\n",
            "    Train data metrics:\n",
            "        AUROC: 0.754167155638562\n",
            "        AUPRC: 0.28642264008522034\n",
            "        Sensitivity: 0.0\n",
            "        Specificity: 1.0\n",
            "y_hat_long sum: 0, target_long sum: 8\n",
            "y_hat_long sum: 0, target_long sum: 6\n",
            "y_hat_long sum: 0, target_long sum: 5\n",
            "y_hat_long sum: 0, target_long sum: 7\n",
            "y_hat_long sum: 0, target_long sum: 4\n",
            "y_hat_long sum: 0, target_long sum: 1\n",
            "y_hat_long sum: 0, target_long sum: 5\n",
            "y_hat_long sum: 0, target_long sum: 2\n",
            "y_hat_long sum: 0, target_long sum: 1\n",
            "y_hat_long sum: 0, target_long sum: 4\n",
            "y_hat_long sum: 0, target_long sum: 2\n",
            "y_hat_long sum: 0, target_long sum: 5\n",
            "y_hat_long sum: 0, target_long sum: 4\n",
            "y_hat_long sum: 0, target_long sum: 3\n",
            "y_hat_long sum: 0, target_long sum: 2\n",
            "y_hat_long sum: 0, target_long sum: 4\n",
            "y_hat_long sum: 0, target_long sum: 3\n",
            "y_hat_long sum: 0, target_long sum: 2\n",
            "y_hat_long sum: 0, target_long sum: 3\n",
            "y_hat_long sum: 0, target_long sum: 4\n",
            "y_hat_long sum: 0, target_long sum: 2\n",
            "y_hat_long sum: 0, target_long sum: 2\n",
            "y_hat_long sum: 0, target_long sum: 3\n",
            "y_hat_long sum: 0, target_long sum: 7\n",
            "y_hat_long sum: 0, target_long sum: 5\n",
            "[tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.)]\n",
            "    Test data metrics:\n",
            "        AUROC: 0.9837161837620654\n",
            "        AUPRC: 0.8320996165275574\n",
            "        Sensitivity: 0.0\n",
            "        Specificity: 1.0\n",
            "====================================\n",
            "     Epoch #6\n",
            "====================================\n",
            "\tBatch 0 loss: 0.3001677393913269\n",
            "\tBatch 1 loss: 0.2395879477262497\n",
            "\tBatch 2 loss: 0.39971041679382324\n",
            "\tBatch 3 loss: 0.2653134763240814\n",
            "\tBatch 4 loss: 0.32391804456710815\n",
            "\tBatch 5 loss: 0.18441614508628845\n",
            "\tBatch 6 loss: 0.5880510210990906\n",
            "\tBatch 7 loss: 0.19164033234119415\n",
            "\tBatch 8 loss: 0.42293667793273926\n",
            "\tBatch 9 loss: 0.15403395891189575\n",
            "\tBatch 10 loss: 0.3635851740837097\n",
            "\tBatch 11 loss: 0.20478582382202148\n",
            "\tBatch 12 loss: 0.2846923768520355\n",
            "\tBatch 13 loss: 0.3075321912765503\n",
            "\tBatch 14 loss: 0.2784319221973419\n",
            "\tBatch 15 loss: 0.3921603560447693\n",
            "\tBatch 16 loss: 0.33248835802078247\n",
            "\tBatch 17 loss: 0.25475409626960754\n",
            "\tBatch 18 loss: 0.32304590940475464\n",
            "y_hat_long sum: 0, target_long sum: 4\n",
            "y_hat_long sum: 0, target_long sum: 2\n",
            "y_hat_long sum: 0, target_long sum: 6\n",
            "y_hat_long sum: 0, target_long sum: 3\n",
            "y_hat_long sum: 0, target_long sum: 4\n",
            "y_hat_long sum: 0, target_long sum: 2\n",
            "y_hat_long sum: 0, target_long sum: 9\n",
            "y_hat_long sum: 0, target_long sum: 2\n",
            "y_hat_long sum: 0, target_long sum: 6\n",
            "y_hat_long sum: 0, target_long sum: 1\n",
            "y_hat_long sum: 0, target_long sum: 5\n",
            "y_hat_long sum: 0, target_long sum: 2\n",
            "y_hat_long sum: 0, target_long sum: 4\n",
            "y_hat_long sum: 0, target_long sum: 4\n",
            "y_hat_long sum: 0, target_long sum: 3\n",
            "y_hat_long sum: 0, target_long sum: 6\n",
            "y_hat_long sum: 0, target_long sum: 5\n",
            "y_hat_long sum: 0, target_long sum: 3\n",
            "y_hat_long sum: 0, target_long sum: 2\n",
            "[tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.)]\n",
            "    Train data metrics:\n",
            "        AUROC: 0.7591483560703021\n",
            "        AUPRC: 0.2881534993648529\n",
            "        Sensitivity: 0.0\n",
            "        Specificity: 1.0\n",
            "y_hat_long sum: 0, target_long sum: 8\n",
            "y_hat_long sum: 0, target_long sum: 6\n",
            "y_hat_long sum: 0, target_long sum: 5\n",
            "y_hat_long sum: 0, target_long sum: 7\n",
            "y_hat_long sum: 0, target_long sum: 4\n",
            "y_hat_long sum: 0, target_long sum: 1\n",
            "y_hat_long sum: 0, target_long sum: 5\n",
            "y_hat_long sum: 0, target_long sum: 2\n",
            "y_hat_long sum: 0, target_long sum: 1\n",
            "y_hat_long sum: 0, target_long sum: 4\n",
            "y_hat_long sum: 0, target_long sum: 2\n",
            "y_hat_long sum: 0, target_long sum: 5\n",
            "y_hat_long sum: 0, target_long sum: 4\n",
            "y_hat_long sum: 0, target_long sum: 3\n",
            "y_hat_long sum: 0, target_long sum: 2\n",
            "y_hat_long sum: 0, target_long sum: 4\n",
            "y_hat_long sum: 0, target_long sum: 3\n",
            "y_hat_long sum: 0, target_long sum: 2\n",
            "y_hat_long sum: 0, target_long sum: 3\n",
            "y_hat_long sum: 0, target_long sum: 4\n",
            "y_hat_long sum: 0, target_long sum: 2\n",
            "y_hat_long sum: 0, target_long sum: 2\n",
            "y_hat_long sum: 0, target_long sum: 3\n",
            "y_hat_long sum: 0, target_long sum: 7\n",
            "y_hat_long sum: 0, target_long sum: 5\n",
            "[tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.), tensor(0.)]\n",
            "    Test data metrics:\n",
            "        AUROC: 0.9846529842514572\n",
            "        AUPRC: 0.8369708061218262\n",
            "        Sensitivity: 0.0\n",
            "        Specificity: 1.0\n",
            "Training stopping after 6 epochs.\n",
            "Loss did not change for 5 epochs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DEBUG - check input data\n",
        "# print(train_set[0].size())\n",
        "for x in range(train_set[0].size()[0]):\n",
        "  cur = train_set[0][x]\n",
        "  nanbread = cur != cur\n",
        "  sumval = nanbread.sum()\n",
        "  if sumval > 0:\n",
        "    print(f'sample {x} has {sumval} nan vals')\n",
        "nanbread = train_set[0] != train_set[0]\n",
        "print(nanbread.sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEyJmm-D2CRa",
        "outputId": "fedb366e-6c26-48cd-fcef-4b28c68dec2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ijm3trFE6UK6"
      },
      "outputs": [],
      "source": [
        "# Put together model as the paper describes (with all resnets)\n",
        "abp_resnet = WaveformResNet(\n",
        "    input_shape=30000,\n",
        "    output_size=32,\n",
        "    data_type='abp'\n",
        ")\n",
        "\n",
        "ecg_resnet = WaveformResNet(\n",
        "    input_shape=30000,\n",
        "    output_size=32,\n",
        "    data_type='ecg'\n",
        ")\n",
        "\n",
        "eeg_resnet = WaveformResNet(\n",
        "    input_shape=7680,\n",
        "    output_size=32,\n",
        "    data_type='eeg'\n",
        ")\n",
        "\n",
        "model = IntraoperativeHypotensionModel(\n",
        "    abp_resnet=abp_resnet,\n",
        "    ecg_resnet=ecg_resnet,\n",
        "    eeg_resnet=eeg_resnet\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFaXjyRytA24"
      },
      "source": [
        "## References\n",
        "Jo YY, Jang JH, Kwon Jm, Lee HC, Jung CW, et al. (2022) Predicting intraoperative hypotension using deep learning with waveforms of arterial blood pressure, electroencephalogram, and electrocardiogram: Retrospective study. PLOS ONE 17(8): e0272055. https://doi.org/10.1371/journal.pone.0272055\n",
        "\n",
        "## Acknowledgements\n",
        "* As mentioned in the introduction, this project leveraged the open [vitaldb dataset](https://vitaldb.net/dataset/), and without it would have been impossible in its current form.\n",
        "* Significant inspiration was drawn from [vital db examples](https://github.com/vitaldb/examples)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "L4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}